{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b30eb052",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/shivanidangal/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a9e00c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk- natural language toolkit\n",
    "import nltk\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d55e95e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gradio\n",
      "  Downloading gradio-3.32.0-py3-none-any.whl (19.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.9/19.9 MB\u001b[0m \u001b[31m928.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pydantic\n",
      "  Downloading pydantic-1.10.8-cp310-cp310-macosx_10_9_x86_64.whl (2.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m962.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from gradio) (1.23.5)\n",
      "Requirement already satisfied: markupsafe in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from gradio) (2.1.1)\n",
      "Collecting mdit-py-plugins<=0.3.3\n",
      "  Using cached mdit_py_plugins-0.3.3-py3-none-any.whl (50 kB)\n",
      "Requirement already satisfied: pillow in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from gradio) (9.4.0)\n",
      "Collecting ffmpy\n",
      "  Using cached ffmpy-0.3.0.tar.gz (4.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting python-multipart\n",
      "  Using cached python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
      "Requirement already satisfied: jinja2 in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from gradio) (3.1.2)\n",
      "Collecting pygments>=2.12.0\n",
      "  Using cached Pygments-2.15.1-py3-none-any.whl (1.1 MB)\n",
      "Requirement already satisfied: matplotlib in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from gradio) (3.7.0)\n",
      "Collecting aiohttp\n",
      "  Using cached aiohttp-3.8.4-cp310-cp310-macosx_10_9_x86_64.whl (358 kB)\n",
      "Collecting semantic-version\n",
      "  Using cached semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Collecting websockets>=10.0\n",
      "  Using cached websockets-11.0.3-cp310-cp310-macosx_10_9_x86_64.whl (120 kB)\n",
      "Requirement already satisfied: typing-extensions in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from gradio) (4.4.0)\n",
      "Collecting uvicorn>=0.14.0\n",
      "  Using cached uvicorn-0.22.0-py3-none-any.whl (58 kB)\n",
      "Collecting markdown-it-py[linkify]>=2.0.0\n",
      "  Using cached markdown_it_py-2.2.0-py3-none-any.whl (84 kB)\n",
      "Collecting pydub\n",
      "  Using cached pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Collecting httpx\n",
      "  Using cached httpx-0.24.1-py3-none-any.whl (75 kB)\n",
      "Collecting orjson\n",
      "  Downloading orjson-3.8.14-cp310-cp310-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (239 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.8/239.8 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from gradio) (1.5.3)\n",
      "Requirement already satisfied: requests in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from gradio) (2.28.1)\n",
      "Collecting gradio-client>=0.2.4\n",
      "  Using cached gradio_client-0.2.5-py3-none-any.whl (288 kB)\n",
      "Requirement already satisfied: pyyaml in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from gradio) (6.0)\n",
      "Collecting fastapi\n",
      "  Using cached fastapi-0.95.2-py3-none-any.whl (56 kB)\n",
      "Collecting altair>=4.2.0\n",
      "  Downloading altair-5.0.1-py3-none-any.whl (471 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.5/471.5 kB\u001b[0m \u001b[31m477.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting aiofiles\n",
      "  Using cached aiofiles-23.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting huggingface-hub>=0.13.0\n",
      "  Using cached huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from altair>=4.2.0->gradio) (4.17.3)\n",
      "Requirement already satisfied: toolz in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from altair>=4.2.0->gradio) (0.12.0)\n",
      "Requirement already satisfied: fsspec in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from gradio-client>=0.2.4->gradio) (2022.11.0)\n",
      "Requirement already satisfied: packaging in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from gradio-client>=0.2.4->gradio) (22.0)\n",
      "Requirement already satisfied: filelock in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from huggingface-hub>=0.13.0->gradio) (3.9.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from huggingface-hub>=0.13.0->gradio) (4.64.1)\n",
      "Collecting mdurl~=0.1\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Collecting linkify-it-py<3,>=1\n",
      "  Downloading linkify_it_py-2.0.2-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from pandas->gradio) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from pandas->gradio) (2022.7)\n",
      "Collecting h11>=0.8\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: click>=7.0 in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from uvicorn>=0.14.0->gradio) (8.0.4)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.3-cp310-cp310-macosx_10_9_x86_64.whl (35 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from aiohttp->gradio) (2.0.4)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.4-cp310-cp310-macosx_10_9_x86_64.whl (29 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from aiohttp->gradio) (22.1.0)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.9.2-cp310-cp310-macosx_10_9_x86_64.whl (65 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.7/65.7 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting starlette<0.28.0,>=0.27.0\n",
      "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting httpcore<0.18.0,>=0.15.0\n",
      "  Downloading httpcore-0.17.2-py3-none-any.whl (72 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: certifi in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from httpx->gradio) (2022.6.15)\n",
      "Requirement already satisfied: idna in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from httpx->gradio) (3.4)\n",
      "Requirement already satisfied: sniffio in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from httpx->gradio) (1.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from matplotlib->gradio) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from matplotlib->gradio) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from matplotlib->gradio) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from matplotlib->gradio) (4.25.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from matplotlib->gradio) (1.0.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from requests->gradio) (1.26.14)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from httpcore<0.18.0,>=0.15.0->httpx->gradio) (3.5.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio) (0.18.0)\n",
      "Collecting uc-micro-py\n",
      "  Downloading uc_micro_py-1.0.2-py3-none-any.whl (6.2 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/shivanidangal/anaconda3/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->gradio) (1.16.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building wheels for collected packages: ffmpy\n",
      "  Building wheel for ffmpy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4693 sha256=9dbe14e501555685652a7b76b3f48eb11c433ede54270f7e79fd12340e3e2853\n",
      "  Stored in directory: /Users/shivanidangal/Library/Caches/pip/wheels/fe/17/e9/577da024bc5aede641c69f0675254c1e518db79800abbe135c\n",
      "Successfully built ffmpy\n",
      "Installing collected packages: pydub, ffmpy, websockets, uc-micro-py, semantic-version, python-multipart, pygments, pydantic, orjson, multidict, mdurl, h11, frozenlist, async-timeout, aiofiles, yarl, uvicorn, starlette, markdown-it-py, linkify-it-py, huggingface-hub, httpcore, aiosignal, mdit-py-plugins, httpx, fastapi, altair, aiohttp, gradio-client, gradio\n",
      "  Attempting uninstall: pygments\n",
      "    Found existing installation: Pygments 2.11.2\n",
      "    Uninstalling Pygments-2.11.2:\n",
      "      Successfully uninstalled Pygments-2.11.2\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.10.1\n",
      "    Uninstalling huggingface-hub-0.10.1:\n",
      "      Successfully uninstalled huggingface-hub-0.10.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spyder 5.4.1 requires pyqt5<5.16, which is not installed.\n",
      "spyder 5.4.1 requires pyqtwebengine<5.16, which is not installed.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed aiofiles-23.1.0 aiohttp-3.8.4 aiosignal-1.3.1 altair-5.0.1 async-timeout-4.0.2 fastapi-0.95.2 ffmpy-0.3.0 frozenlist-1.3.3 gradio-3.32.0 gradio-client-0.2.5 h11-0.14.0 httpcore-0.17.2 httpx-0.24.1 huggingface-hub-0.14.1 linkify-it-py-2.0.2 markdown-it-py-2.2.0 mdit-py-plugins-0.3.3 mdurl-0.1.2 multidict-6.0.4 orjson-3.8.14 pydantic-1.10.8 pydub-0.25.1 pygments-2.15.1 python-multipart-0.0.6 semantic-version-2.10.0 starlette-0.27.0 uc-micro-py-1.0.2 uvicorn-0.22.0 websockets-11.0.3 yarl-1.9.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0d86958e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gradio is used for creating UI components\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85ba24d",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a1231f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_tokenization(input):\n",
    "    token= word_tokenize(input)\n",
    "    return token\n",
    "def sent_tokenization(input):\n",
    "    token= sent_tokenize(input)\n",
    "    return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ffd8770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_tokenization= gr.Interface(word_tokenization, inputs=\"text\", outputs=\"text\")\n",
    "demo_tokenization.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86e602ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7867\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7867/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo= gr.Blocks()\n",
    "with demo:\n",
    "    gr.Markdown(\"Tokenization\")\n",
    "    with gr.Tabs():\n",
    "        with gr.TabItem(\"Word Tokenization\"):\n",
    "            with gr.Row():\n",
    "                word_ip= gr.Textbox(label=\"Input Data\")\n",
    "                word_op= gr.Textbox(label=\"Output Data\")\n",
    "                word_btn= gr.Button(\"Generate Tokens\")\n",
    "        with gr.TabItem(\"Sentence Tokenization\"):\n",
    "            with gr.Row():\n",
    "                sent_ip= gr.Textbox(label=\"Input Data\")\n",
    "                sent_op= gr.Textbox(label=\"Output Data\")\n",
    "                sent_btn= gr.Button(\"Generate Tokens\")\n",
    "    word_btn.click(word_tokenization, inputs=word_ip, outputs=word_op)\n",
    "    sent_btn.click(sent_tokenization, inputs=sent_ip, outputs=sent_op)\n",
    "    \n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510f5b7c",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "43187f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7879\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7879/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowball_stemmer= SnowballStemmer('english')\n",
    "def stemming(text):\n",
    "    tokenize_words= word_tokenize(text)\n",
    "    stemmed_list= [snowball_stemmer.stem(words) for words in tokenize_words]\n",
    "    return stemmed_list\n",
    "\n",
    "demo_stemming= gr.Interface(stemming, inputs=\"text\", outputs=\"text\")\n",
    "demo_stemming.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5fc2af67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['{',\n",
       " '\\\\rtf1\\\\ansi\\\\ansicpg1252\\\\cocoartf2709',\n",
       " '\\\\cocoatextscaling0\\\\cocoaplatform0',\n",
       " '{',\n",
       " '\\\\fonttbl\\\\f0\\\\fswiss\\\\fcharset0',\n",
       " 'helvetica',\n",
       " ';',\n",
       " '}',\n",
       " '{',\n",
       " '\\\\colortbl',\n",
       " ';',\n",
       " '\\\\red255\\\\green255\\\\blue255',\n",
       " ';',\n",
       " '}',\n",
       " '{',\n",
       " '\\\\',\n",
       " '*',\n",
       " '\\\\expandedcolortbl',\n",
       " ';',\n",
       " ';',\n",
       " '}',\n",
       " '\\\\paperw11900\\\\paperh16840\\\\margl1440\\\\margr1440\\\\vieww11520\\\\viewh8400\\\\viewkind0',\n",
       " '\\\\pard\\\\tx720\\\\tx1440\\\\tx2160\\\\tx2880\\\\tx3600\\\\tx4320\\\\tx5040\\\\tx5760\\\\tx6480\\\\tx7200\\\\tx7920\\\\tx8640\\\\pardirnatural\\\\partightenfactor0',\n",
       " '\\\\f0\\\\fs24',\n",
       " '\\\\cf0',\n",
       " 'hi',\n",
       " ',',\n",
       " 'shivani',\n",
       " 'here',\n",
       " '.',\n",
       " 'hope',\n",
       " 'you',\n",
       " 'are',\n",
       " 'do',\n",
       " 'well',\n",
       " 'i',\n",
       " 'just',\n",
       " 'want',\n",
       " 'to',\n",
       " 'convey',\n",
       " 'that',\n",
       " 'i',\n",
       " 'am',\n",
       " 'interest',\n",
       " 'in',\n",
       " 'particip',\n",
       " 'in',\n",
       " 'the',\n",
       " 'contest',\n",
       " '.',\n",
       " 'look',\n",
       " 'forward',\n",
       " 'to',\n",
       " 'work',\n",
       " 'with',\n",
       " 'you',\n",
       " '.',\n",
       " '}']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp1= open('stopwords.txt.rtf','r')\n",
    "input1= fp1.read()\n",
    "stemming(input1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d251845",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b383bd72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/shivanidangal/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7c3711bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/shivanidangal/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1ad4cf42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7871\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7871/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer= WordNetLemmatizer()\n",
    "def lemmatization(text):\n",
    "    word_tokens= word_tokenize(text)\n",
    "    lemma= [lemmatizer.lemmatize(words) for words in word_tokens]\n",
    "    return lemma\n",
    "\n",
    "demo_lemma= gr.Interface(lemmatization, inputs=\"text\", outputs=\"text\")\n",
    "demo_lemma.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d316c2d9",
   "metadata": {},
   "source": [
    "# Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "03962500",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/shivanidangal/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "63eb4074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7875\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7875/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words= stopwords.words('english')\n",
    "def stopwords_removal(text):\n",
    "    word_tokens= word_tokenize(text)\n",
    "    filtered_sent= [w for w in word_tokens if w.lower() not in stop_words]\n",
    "    filtered_sent=[]\n",
    "    for w in word_tokens:\n",
    "        if w not in stop_words:\n",
    "            filtered_sent.append(w)\n",
    "    return filtered_sent\n",
    "\n",
    "demo_stopwords= gr.Interface(stopwords_removal, inputs=\"text\", outputs=\"text\")\n",
    "demo_stopwords.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2887efc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['{\\\\rtf1\\\\ansi\\\\ansicpg1252\\\\cocoartf2709', '\\\\cocoatextscaling0\\\\cocoaplatform0{\\\\fonttbl\\\\f0\\\\fswiss\\\\fcharset0', 'Helvetica;}', '{\\\\colortbl;\\\\red255\\\\green255\\\\blue255;}', '{\\\\*\\\\expandedcolortbl;;}', '\\\\paperw11900\\\\paperh16840\\\\margl1440\\\\margr1440\\\\vieww11520\\\\viewh8400\\\\viewkind0', '\\\\pard\\\\tx720\\\\tx1440\\\\tx2160\\\\tx2880\\\\tx3600\\\\tx4320\\\\tx5040\\\\tx5760\\\\tx6480\\\\tx7200\\\\tx7920\\\\tx8640\\\\pardirnatural\\\\partightenfactor0', '\\\\f0\\\\fs24', '\\\\cf0', 'Hi,', 'Shivani', 'here.', 'Hope', 'well', 'I', 'wanted', 'convey', 'I', 'interested', 'participating', 'contest.', 'Looking', 'forward', 'work', 'you.}']\n"
     ]
    }
   ],
   "source": [
    "fp= open('stopwords.txt.rtf','r')\n",
    "file= fp.read()\n",
    "inp= file.split()\n",
    "def stopwords_file(text):\n",
    "    filtered= [w for w in text if w.lower() not in stop_words]\n",
    "    filtered= []\n",
    "    for w in text:\n",
    "        if w not in stop_words:\n",
    "            filtered.append(w)\n",
    "    return filtered\n",
    "result= stopwords_file(inp)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3563ed0",
   "metadata": {},
   "source": [
    "# POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5f23319a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/shivanidangal/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4457df00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7880\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7880/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pos(text):\n",
    "    word_tokens= word_tokenize(text)\n",
    "    pos_list= nltk.pos_tag(word_tokens)\n",
    "    return pos_list\n",
    "\n",
    "demo_pos= gr.Interface(pos, inputs=\"text\", outputs=\"text\")\n",
    "demo_pos.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "89258897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('{', '('), ('\\\\rtf1\\\\ansi\\\\ansicpg1252\\\\cocoartf2709', 'VB'), ('\\\\cocoatextscaling0\\\\cocoaplatform0', 'NNP'), ('{', '('), ('\\\\fonttbl\\\\f0\\\\fswiss\\\\fcharset0', 'NNP'), ('Helvetica', 'NNP'), (';', ':'), ('}', ')'), ('{', '('), ('\\\\colortbl', 'JJ'), (';', ':'), ('\\\\red255\\\\green255\\\\blue255', 'CC'), (';', ':'), ('}', ')'), ('{', '('), ('\\\\', 'JJ'), ('*', 'NNP'), ('\\\\expandedcolortbl', 'NNP'), (';', ':'), (';', ':'), ('}', ')'), ('\\\\paperw11900\\\\paperh16840\\\\margl1440\\\\margr1440\\\\vieww11520\\\\viewh8400\\\\viewkind0', 'FW'), ('\\\\pard\\\\tx720\\\\tx1440\\\\tx2160\\\\tx2880\\\\tx3600\\\\tx4320\\\\tx5040\\\\tx5760\\\\tx6480\\\\tx7200\\\\tx7920\\\\tx8640\\\\pardirnatural\\\\partightenfactor0', 'JJ'), ('\\\\f0\\\\fs24', 'NNP'), ('\\\\cf0', 'NNP'), ('Hi', 'NNP'), (',', ','), ('Shivani', 'NNP'), ('here', 'RB'), ('.', '.'), ('Hope', 'NNP'), ('you', 'PRP'), ('are', 'VBP'), ('doing', 'VBG'), ('well', 'RB'), ('I', 'PRP'), ('just', 'RB'), ('wanted', 'VBD'), ('to', 'TO'), ('convey', 'VB'), ('that', 'IN'), ('I', 'PRP'), ('am', 'VBP'), ('interested', 'JJ'), ('in', 'IN'), ('participating', 'VBG'), ('in', 'IN'), ('the', 'DT'), ('contest', 'NN'), ('.', '.'), ('Looking', 'VBG'), ('forward', 'RB'), ('to', 'TO'), ('work', 'VB'), ('with', 'IN'), ('you', 'PRP'), ('.', '.'), ('}', ')')]\n"
     ]
    }
   ],
   "source": [
    "print(pos(input1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988ee266",
   "metadata": {},
   "source": [
    "# TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3f0d2710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF values:\n",
      "  (0, 8)\t0.7071067811865476\n",
      "  (0, 4)\t0.7071067811865476\n",
      "  (1, 9)\t0.4403620672313486\n",
      "  (1, 6)\t0.4403620672313486\n",
      "  (1, 2)\t0.3349067026613031\n",
      "  (1, 0)\t0.4403620672313486\n",
      "  (1, 1)\t0.4403620672313486\n",
      "  (1, 8)\t0.3349067026613031\n",
      "  (2, 5)\t0.49047908420610337\n",
      "  (2, 3)\t0.49047908420610337\n",
      "  (2, 7)\t0.49047908420610337\n",
      "  (2, 2)\t0.3730219858594306\n",
      "  (2, 4)\t0.3730219858594306\n",
      "IDF values:\n",
      "daily : 1.6931471805599454\n",
      "do : 1.6931471805599454\n",
      "exercise : 1.2876820724517808\n",
      "for : 1.6931471805599454\n",
      "good : 1.2876820724517808\n",
      "health : 1.6931471805599454\n",
      "in : 1.6931471805599454\n",
      "is : 1.6931471805599454\n",
      "morning : 1.2876820724517808\n",
      "the : 1.6931471805599454\n",
      "Indexes: {'good': 4, 'morning': 8, 'do': 1, 'daily': 0, 'exercise': 2, 'in': 6, 'the': 9, 'is': 7, 'for': 3, 'health': 5}\n"
     ]
    }
   ],
   "source": [
    "d0= \"good morning\"\n",
    "d1= \"do daily exercise in the morning\"\n",
    "d2= \"exercise is good for health\"\n",
    "series= [d0,d1,d2]\n",
    "\n",
    "tfidf=TfidfVectorizer()\n",
    "\n",
    "#tf-idf values\n",
    "res= tfidf.fit_transform(series)\n",
    "print('TF values:')\n",
    "print(res)\n",
    "\n",
    "#idf values\n",
    "print('IDF values:')\n",
    "for ele1, ele2 in zip(tfidf.get_feature_names_out(), tfidf.idf_):\n",
    "    print(ele1,\":\",ele2)\n",
    "    \n",
    "print('Indexes:', tfidf.vocabulary_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50c4082",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
